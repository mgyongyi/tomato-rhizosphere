{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab eBook \n",
    "\n",
    "Research Journal to keep a record of daily achievements and performance through out the research project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 1 - Sept 5th - Sept 9th \n",
    "\n",
    "__Sept 5__ \n",
    "\n",
    "- Intro talk with Anna\n",
    "- Chrunchomics documentation and tutorial, resulting in configuration of personal account \n",
    "- Entered the omics server through the head node and explored: ssh -X 14108550@omics-h0.science.uva.nl \n",
    "- IMP3 documentation: https://imp3.readthedocs.io/en/latest/ \n",
    "\n",
    "__Sept 6__ \n",
    "\n",
    "\n",
    "- Checklist:\n",
    "    - Installed miniconda on omics server personal account \n",
    "    - Watched Lecture 1 of Metagenomics course\n",
    "        - lecture 1: https://video.uva.nl/media/Metagenomics+101+-+1%7C+overview+-+private+version/0_pvgszh0o \n",
    "            - definition of metagenomics\n",
    "            - brief history of metagenomics\n",
    "            - glimpse into raw data\n",
    "            - typical steps in an analysis\n",
    "        - Metagenomics 101: https://staff.fnwi.uva.nl/a.u.s.heintzbuschart/metagenomics_00.html \n",
    "    - Completed Tutorial 1 of Metagenomics course \n",
    "        - Set up: didn't initialize miniconda since it had already been used before and saved data in personal directory.\n",
    "        - First test-run of IMP3 in Crunchomics - dry run to test configuration_\n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d my.config.yaml\n",
    "            - desired output: This was a dry-run (flag -n). The order of jobs does __not__ reflect the order of execution.\n",
    "        - Submitted the first test run to the compute nodes of crunchomics server in node 3 with omics-cn003.\n",
    "            - first check the available nodes: sinfo -o \"%n %e %m %a %c %C\" \n",
    "        - IMP3 inputs: data and configuration file \n",
    "            - my.config.yaml configuration file is the only required argument and specifies the input data. \n",
    "            - code used to commit the real run to the compute node, which includes more arguments than the previous dry run: \n",
    "                - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn002 my.config.yaml \n",
    "    - Read Snakemake documentation \n",
    "        - Tutorial: https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html#\n",
    "        - Academic Article: https://f1000research.com/articles/10-33/v2 \n",
    "        - website: https://snakemake.github.io/  \n",
    "    - Created github repository and started lab eBook\n",
    "\n",
    "\n",
    "__Sept 7__ \n",
    "\n",
    "- Checklist:\n",
    "    - Metagenomics Lecture 2: Raw Data Preprocessing and QC \n",
    "        - .fastq files tools resource: http://barcwiki.wi.mit.edu/wiki/SOPs/qc_shortReads \n",
    "        - brief look into different sequencing techniques\n",
    "        - what can go wrong when sequencing\n",
    "        - sequencing quality scores\n",
    "        - quality reports\n",
    "        - adapter, spike-in, and host genome removal (the host microbiome needs to be removed because you are interested in the other genomes in the sample)\n",
    "    - Metagenomics Tutorial 2: Run Preprocessing on Toy Data\n",
    "        - Finding Novaseq file in reads data - the GCEF.test.r1.fq and GCEF.test.r2.fq are novaseq\n",
    "        - code used to modify the configuration file __prep.1.config.yaml__ to use datasets COSMIC_vag.test.r1.fq and COSMIC_vag.test.r2.fq instead of the default test data, by manually changing inside the configuration file by using nano command: \n",
    "            - raws:\n",
    "                Metagenomics: \"/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r1.fq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r2.fq\"\n",
    "        - made a copy of prep.1.config.yaml to be able to run both configuration at the same time and have their own output directories. \n",
    "        - code used to modify the configuration file __prep.2.config.yaml__ to use datasets GCEF.test.r1.fq and GCEF.test.r2.fq instead of the default test data, by manually changing inside the configuration file by using __nano__ command: \n",
    "            - raws:\n",
    "                Metagenomics: \"/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/GCEF.test.r1.fq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/GCEF.test.r2.fq\"\n",
    "            - also changed the output directory to __IMP3_test_preprocessing_novaseq__, and nextseq argument to __true__. \n",
    "        - performed the dry run and obtained desired output:\n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d prep.1.config.yaml \n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d prep.2.config.yaml \n",
    "        - both runs were commited to node 2:\n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn002 prep.1.config.yaml\n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn002 prep.2.config.yaml\n",
    "        - The dataset COSMIC_vag.test.r1|2.fq comes from a sample that contains still host genomics DNA\n",
    "            - prep.1.config.yaml was copied to prep.3.config.yaml and a new configuration was specified with the same test data, a new output directory __IMP3_test_preprocessing_hg38filtering__, and the filtering was specified to hg38 to filter out the human genome \n",
    "            - dry run was performed and successful \n",
    "            - run was submitted to node 4: \n",
    "                - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn004 prep.3.config.yaml\n",
    "    - read IMP3 documentation \n",
    "    - read Research project rubric \n",
    "    - read antiSMASH paper \n",
    "\n",
    "\n",
    "__Sept 8__ \n",
    "\n",
    "- checklist:\n",
    "    - Metagenomics 101 Lecture 3: Mapping Metagenomics read data to reference genomes \n",
    "        - why mapping\n",
    "        - bioinformatics for sequence alignment\n",
    "        - look at output (alignments) created by read mappers\n",
    "        - what can be done with the output  \n",
    "    - Tutorial 3:\n",
    "        - not IMP3 pipeline but the commands on their own  \n",
    "        - environments IMP3 provides on crunchomics to preprocess data with BWA-MEM - Burrows Wheeler algoritm (transform) - Maximum Exact Matches \n",
    "        1. Running BWA-MEM indexing \n",
    "            - build index of references (don't do on the frontend if using a real genomes, okay now bc test data)\n",
    "            - cp /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/REFERENCES/mg.assembly.merged.fa . (copied to my personal directory)\n",
    "            - conda activate /zfs/omics/projects/metatools/TOOLS/IMP3/conda/76e02d85877600c41ac84cb7bc27a189\n",
    "            - bwa index mg.assembly.merged.fa \n",
    "        2. Running mapping with BWA-MEM \n",
    "            - bwa mem -v 1 -t 1  mg.assembly.merged.fa /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.1.fastq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.2.fastq >> test_alignment.sam\n",
    "            - you can run other data, for examble: COMSIC_vag.test.r1|r2.fq with the hg38.fa - first need to find hg38.fa file to copy to personal directory and index it \n",
    "        3. Take a look at the alignment file \n",
    "            - output of BWA-MEM is an alignment file in .sam format. Alignment information is at the end of the file \n",
    "            - tail test_alignment.sam \n",
    "        4. Converting the alignment file to a binary (compressed) format \n",
    "            - convert to .bam format because the .sam is very big and you don't want to store on own disk \n",
    "            - samtools view --threads 1 -bS test_alignment.sam > test_alignment.bam\n",
    "            - can also be donde in one step with the mapping: \n",
    "                - bwa mem -v 1 -t 1  /zfs/omics/projects/metatools/DB/filtering/hg38.fa /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r1.fq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r2.fq |\\\n",
    "                    samtools view --threads 1 -bS - > COSMIC_alignment.bam\n",
    "            - can look at a .bam file with samtools view: samtools view test_alignment.bam | less\n",
    "        5. Filtering the .bam file \n",
    "            - also using samtools view, use -f 4 to find only reads which don't map to reference \n",
    "            - samtools view -f 4 test_alignment.bam | less \n",
    "            - this shows many of the values to be 0 \n",
    "            - -F 4 give reads which map (careful, there's also a second read)\n",
    "            - more samtools flags: https://broadinstitute.github.io/picard/explain-flags.html\n",
    "            - samtools manual: http://www.htslib.org/doc/samtools-view.html \n",
    "        6. More complex filtering \n",
    "            - used in IMP3 to remove reads mapping to a host genome \n",
    "            - samtools merge --threads 1 -u - \\\n",
    "                <(samtools view --threads 1 -u  -f 4 -F 264 COSMIC_alignment.bam) \\\n",
    "                <(samtools view --threads 1 -u -f 8 -F 260 COSMIC_alignment.bam) \\\n",
    "                <(samtools view --threads 1 -u -f 12 -F 256 COSMIC_alignment.bam)  | \\\n",
    "            samtools view --threads 1 -bF 0x800 - | \\\n",
    "            samtools sort --threads 1 -m 3G -n - | \\\n",
    "            bamToFastq -i stdin -fq COSMIC_filtered.r1.fq -fq2 COSMIC_filtered.r2.fq\n",
    "\n",
    "            conda deactivate \n",
    "            (all COSMIC_alignment.bam files are the test_alignment.bam files when doing the alignment of COSMIC files to the hg38.fa reference genome - didn't actually perform that alignment) (figure out what the code on top is doing by looking at the resources of flags and samtools documentation)\n",
    "    - read papers \n",
    "    - read Research project rubric \n",
    "    - understand IMP3 documentation very well \n",
    "    - review crunchomics documentation (SLURMs)\n",
    "\n",
    "\n",
    "__Sept 9__ \n",
    "\n",
    "- 11 am meeting with Anna \n",
    "    - where data will go \n",
    "    - expectations\n",
    "    - research project rubric \n",
    "    - questions:\n",
    "        - trial presentation 1-2 weeks before final presentation - november \n",
    "        - final presentation 2 weeks after final draft submitted - schedule myself \n",
    "        - is it confidential? NOT \n",
    "        - examiner final presentation availability - once a month on a friday \n",
    "        - DeskForm mentioned that days off should be accounted for and arranged for another time. \n",
    "        - miniconda33 mistake - uninstalled - reinstall \n",
    "    - meeting notes:\n",
    "        - project data is not nextseq \n",
    "        - will start setting up assemblies next week\n",
    "        - I need to send CV and information for the job contract \n",
    "        - fix miniconda3 installation \n",
    "        - GO/NOGO meeting with plant research group during second week of October \n",
    "        - there are 54 samples in the project data set \n",
    "\n",
    "- checklist:\n",
    "    - watch metagenomics lecture 4: Taxonomy\n",
    "        - different approaches toprofile microbiomes in terms of the present taxa, using metagenomics read data \n",
    "        - introduction into the aims and particular environments \n",
    "        - a touch of taxonomy \n",
    "        - brief reminder of mapping of metagenomis reads \n",
    "        - look at non-alignment based profilers \n",
    "        - how taxonomic profilers are benchmarked \n",
    "        - what we can do with this output \n",
    "    - Tutorial 4: Run mOTUs2, MetaPhlan2, and kraken2\n",
    "        - Use the taxonomic profiles in the IMP3 pipeline as well as MetaPhlan3 (IMP3 in crunchomics and metaphlan3 conda environment)\n",
    "        - use cd /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS files or the preprocessed files from the last sessions\n",
    "        - Running taxonomic profiling within __IMP3__ \n",
    "            - start IMP3 with an appropriate configuration file since data is preprocessed. Set config file to not do preprocessing, and set input as already preprocessed files\n",
    "            > cp /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/04_taxonomy1/tax.config.yaml my.tax.config.yaml \n",
    "            - change (using nano) to input own data. Can also change the kraken databse to one of the names in /zfs/omics/projects/metatools/DB with the word kraken in it (UHGP_kraken2 for human gut genomes, minikraken2 for an even smaller database; kraken_pfp8 is the current kraken db in configuration). Output directory: test_tax_output\n",
    "                >raws:\n",
    "                >>Metagenomics: /home/14108550/personal/IMP3_test_preprocessing/Preprocessing/mg.r1.trimmed.phiX174_filtered.fq\n",
    "                >>/home/14108550/personal/IMP3_test_preprocessing/Preprocessing/mg.r2.trimmed.phiX174_filtered.fq\n",
    "                >>/home/14108550/personal/IMP3_test_preprocessing/Preprocessing/mg.se.trimmed.phiX174_filtered.fq\n",
    "            - first did dry run, which was successful \n",
    "            > /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d my.tax.config.yaml\n",
    "            - then commited run to node 3 \n",
    "            > /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTTAX -b omics-cn003 my.tax.config.yaml\n",
    "            - inside the output directory will be another directory Analysis/taxonomy which holds the outputs from mOTUs2 and kraken2 \n",
    "        - Taxonomic profiling using __MetaPhlan3__\n",
    "            - works very well on human samples and has a strain-level module. \n",
    "            - activate the conda environment: \n",
    "            > conda activate /zfs/omics/projects/metatools/TOOLS/miniconda3/envs/metaphlan-3.0\n",
    "            - to get help and documentation on the profiler:\n",
    "            > metaphlan -h \n",
    "            - example to run on filtered test reads:\n",
    "            > metaphlan /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/FILTERED_READS/mg.r1.trimmed.phiX174_filtered.fq,/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/FILTERED_READS/mg.r2.trimmed.phiX174_filtered.fq,/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/FILTERED_READS/mg.se.trimmed.phiX174_filtered.fq --bowtie2out filtered_test.bowtie2.bz2 --input_type fastq -o profile.filtered_test.txt  --bowtie2db /zfs/omics/projects/metatools/DB/metaphlan --unknown_estimation\n",
    "            - can also run on own filtered reads instead. to run on real data set, put the commands to activate (and deactivate) conda and the metaphlan command into a script that you submit to the cluster. You can then also choose to set the --nproc argument (--nproc 8 to parallelize the profiling) \n",
    "            - code for runnin the non-filtered reads \n",
    "            > metaphlan /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.r1.fastq,/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.r2.fastq --bowtie2out unfiltered_test.bowtie2.bz2 --input_type fastq -o profile.unfiltered_test.txt  --bowtie2db /zfs/omics/projects/metatools/DB/metaphlan --unknown_estimation\n",
    "            - To merge the profiles from several samples (or in this case, the same sample, but represented by filtered or unfiltered reads), you can use metaphlan’s merge script\n",
    "            > merge_metaphlan_tables.py profile*filtered_test.txt > merged_abundance.test.tsv\n",
    "            - to compare the results:\n",
    "            > less merged_abundance.test.tsv\n",
    "            > conda deactivate\n",
    "            \n",
    "    - read papers \n",
    "    - finish metagenomics tutorials to start working on project data next week \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 2 Sept 12 - Sept 16 \n",
    "\n",
    "__Sept 12__\n",
    "\n",
    "- checklist:\n",
    "    - Metagenomics 101 Lecture 5: Assembly\n",
    "        - lecture video: https://video.uva.nl/media/Metagenomics+101+-+5%7C+Assembly+-+private+version/0_p8gnde38 \n",
    "        - why assemble\n",
    "        - alternatives to assembly\n",
    "        - how does assembly work\n",
    "        - how to inspect assemblies\n",
    "        - what to assemble \n",
    "        - stopped at min 17 \n",
    "    - Tutorial 5: Run assemblies in IMP3 \n",
    "        - assemble with IMP3 and look at diagnostic plots \n",
    "\n",
    "__Sept 13__\n",
    "\n",
    "- 11 am meeting with Anna \n",
    "    - srun -w omics-cn002 --pty bash (to access a node's bash) \n",
    "    - ls -lh (to see the details of contents in a directory)\n",
    "    - /zfs/omics/projects/metatools/TOOLS/IMP3/config/config.imp.yaml (IMP3 default config file with some explanations)\n",
    "    - 2 controls and 3 different gene transforms for tomato plant lines, also 1 negative control (no plant, just soil) \n",
    "    - make a logs and configs directories and commit runs through logs \n",
    "- Might start setting up assemblies \n",
    "- Bora's data: /zfs/omics/projects/phb/bora/test/all_samples \n",
    "- made personal directories in the /scratch of each node \n",
    "- commit to nodes:\n",
    "    > run dry runs of config files in a computation node by entering the node and running from there in the logs directory: /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d ../configs/T_712_2.assembly.config.yaml (done for each of the config files)\n",
    "    - sinfo -o \"%n %e %m %a %c %C\"\n",
    "    - squeue -u 14108550\n",
    "    - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n T_712_2 -b omics-cn003 ../configs/T_712_2.assembly.config.yaml\n",
    "    - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n T_712_4 -b omics-cn004 ../configs/T_712_4.assembly.config.yaml\n",
    "    - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n T_712_6 -b omics-cn005 ../configs/T_712_6.assembly.config.yaml\n",
    "\n",
    "__Sept 14__\n",
    "\n",
    "- Checklist: \n",
    "    - Metagenomics Lecture 6: Metagenome Annotation (of assembled contigs)\n",
    "        - finding bacterial genes\n",
    "            - protein coding genes\n",
    "            - rRNAs\n",
    "        - annotating genes with functions\n",
    "            - why not just align?\n",
    "            - HMMs and HMMER\n",
    "    - Tutorial 6: \n",
    "\n",
    "__Sept 15__\n",
    "\n",
    "- 1 pm meeting with Anna \n",
    "    - What to do with assembled and analyzed (annotated) reads \n",
    "\n",
    "\n",
    "\n",
    "__Sept 16__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
