{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab eBook \n",
    "\n",
    "Research Journal to keep a record of daily achievements and performance through out the research project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 1 - Sept 5th - Sept 9th "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sept 5__ \n",
    "\n",
    "- Intro talk with Anna\n",
    "- Chrunchomics documentation and tutorial, resulting in configuration of personal account \n",
    "- Entered the omics server through the head node and explored: ssh -X 14108550@omics-h0.science.uva.nl \n",
    "- IMP3 documentation: https://imp3.readthedocs.io/en/latest/ \n",
    "\n",
    "__Sept 6__ \n",
    "\n",
    "- Checklist:\n",
    "    - Installed miniconda on omics server personal account \n",
    "    - Watched Lecture 1 of Metagenomics course\n",
    "    - Completed Tutorial 1 of Metagenomics course \n",
    "    - Read Snakemake documentation \n",
    "        - Tutorial: https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html#\n",
    "        - Academic Article: https://f1000research.com/articles/10-33/v2 \n",
    "        - website: https://snakemake.github.io/  \n",
    "    - Created github repository and started lab eBook\n",
    "\n",
    "__Sept 7__ \n",
    "\n",
    "- Checklist:\n",
    "    - Metagenomics Lecture 2: Raw Data Preprocessing and QC \n",
    "    - Metagenomics Tutorial 2: Run Preprocessing on Toy Data\n",
    "    - read IMP3 documentation \n",
    "    - read Research project rubric \n",
    "    - read antiSMASH paper \n",
    "\n",
    "__Sept 8__ \n",
    "\n",
    "- checklist:\n",
    "    - Metagenomics 101 Lecture 3: Mapping Metagenomics read data to reference genomes \n",
    "    - read papers \n",
    "    - read Research project rubric \n",
    "    - understand IMP3 documentation very well \n",
    "    - review crunchomics documentation (SLURMs)\n",
    "\n",
    "\n",
    "__Sept 9__ \n",
    "\n",
    "- 11 am meeting with Anna \n",
    "    - where data will go \n",
    "    - expectations\n",
    "    - research project rubric \n",
    "    - questions:\n",
    "        - trial presentation 1-2 weeks before final presentation - november \n",
    "        - final presentation 2 weeks after final draft submitted - schedule myself \n",
    "        - is it confidential? NOT \n",
    "        - examiner final presentation availability - once a month on a friday \n",
    "        - DeskForm mentioned that days off should be accounted for and arranged for another time. \n",
    "        - miniconda33 mistake - uninstalled - reinstall \n",
    "    - meeting notes:\n",
    "        - project data is not nextseq \n",
    "        - will start setting up assemblies next week\n",
    "        - I need to send CV and information for the job contract \n",
    "        - fix miniconda3 installation \n",
    "        - GO/NOGO meeting with plant research group during second week of October \n",
    "        - there are 54 samples in the project data set \n",
    "\n",
    "- checklist:\n",
    "    - watch metagenomics lecture 4: Taxonomy & Tutorial \n",
    "    - read papers \n",
    "    - finish metagenomics tutorials to start working on project data next week \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 2 Sept 12 - Sept 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sept 12__\n",
    "\n",
    "- checklist:\n",
    "    - Metagenomics 101 Lecture 5: Assembly & Tutorial \n",
    "\n",
    "__Sept 13__\n",
    "\n",
    "- 11 am meeting with Anna \n",
    "    - srun -w omics-cn002 --pty bash (to access a node's bash) \n",
    "    - ls -lh (to see the details of contents in a directory)\n",
    "    - /zfs/omics/projects/metatools/TOOLS/IMP3/config/config.imp.yaml (IMP3 default config file with some explanations)\n",
    "    - 2 controls and 3 different gene transforms for tomato plant lines, also 1 negative control (no plant, just soil) \n",
    "    - make a logs and configs directories and commit runs through logs \n",
    "- Might start setting up assemblies \n",
    "- Bora's data: /zfs/omics/projects/phb/bora/test/all_samples \n",
    "- made personal directories in the /scratch of each node \n",
    "- commit to nodes:\n",
    "    > run dry runs of config files in a computation node by entering the node and running from there in the logs directory: /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d ../configs/T_712_2.assembly.config.yaml (done for each of the config files)\n",
    "- sinfo -o \"%n %e %m %a %c %C\"\n",
    "- squeue -u 14108550\n",
    "- -b works only with -c and bind the run to a node \n",
    "- /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -h (for more information on the input flags)\n",
    "    > /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n T_712_2 -b omics-cn003 ../configs/T_712_2.assembly.config.yaml\n",
    "    > /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n T_712_4 -b omics-cn004 ../configs/T_712_4.assembly.config.yaml\n",
    "    > /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n T_712_6 -b omics-cn005 ../configs/T_712_6.assembly.config.yaml\n",
    "\n",
    "__Sept 14__\n",
    "\n",
    "- Metagenomics Lecture 6 and Tutorial\n",
    "\n",
    "__Sept 15__\n",
    "\n",
    "- Observed that Tuesday's runs were done so submitted 5 more into the computation nodes, one for each node, after successfully running dry runs for each one. Submitted the first 5 samples for T_722 plant line, in ascending order. \n",
    "- 1:30 pm meeting with Anna \n",
    "    - What to do with assembled and analyzed (annotated) reads -> start running antiSMASH \n",
    "    - is there a 9 am meeting tomorrow? NO\n",
    "    - github repository \n",
    "    - how long will the GO/NOGO presentation be? 20 mins\n",
    "    - agriculture and crop management or another aim? -> fundamental microorganisms and plant interactions\n",
    "    - wait until all the assemblies are done to analyse the functional abundance differences. or how to build functional profiles from the assembly and annotation? \n",
    "    - notes:\n",
    "        - **copy the report.html into my personal and then download to my computer to observe the running times and how it all went, if it got stuck somewhere or something**\n",
    "        - **also check the status directory in each sample to make sure everything is fine**\n",
    "        - **delete Preprocessing directory after runs are finished after status is checked, to free up space**\n",
    "        - annotation_CDS_RNA_hmms.gff\tannotation.filt.gff, both of this in Analysis/annotation are the final annotation files that can either be inputs into antiSMASH, check which one is accepted\n",
    "        - the assembly output file to use for antiSMASH: mg.assembly.merged.fa \n",
    "        - can use either a fundamental scope of research to look at interaction between microbiomes and plants to make it more application focused and talk about crop management and agriculture \n",
    "        - always run antiSMASH for a sample in the same computation node as IMP3 assembly was done, to be able to access the input files from scratch \n",
    "        - all of the .counts. files in Analysis/annotation is the analysis of mapped count reads to the assembled genome for each of the specific databases used. \n",
    "        - **figure out antiSMASH on my own**\n",
    "\n",
    "\n",
    "\n",
    "__Sept 16__\n",
    "\n",
    "- antismash\n",
    "    > conda activate /zfs/omics/projects/metatools/TOOLS/miniconda3/envs/antismash6/ \n",
    "    > antismash -h (to learn how to run it with flags and everything)\n",
    "    > conda deactivate once done using it \n",
    "- to move files from remote server to local do ifconfig -a to get inet IP adress, first one, and then do the following code from a local terminal to pull the file to local. the . is to indicate the directory if you're already in that directory \n",
    "> scp 14108550@146.50.10.60:/home/14108550/personal/Samples_Outputs/T_712_2_report.html .\n",
    "- do scancel +number of run to cancel a run \n",
    "- rm -r Preprocessing (to delete directory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 3 Sept 19 - Sept 23 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sept 19__\n",
    "\n",
    "- Metagenomics 101 Lecture 7 \n",
    "- antiSMASH documentation \n",
    "    - conda activate /zfs/omics/projects/metatools/TOOLS/miniconda3/envs/antismash6\n",
    "    - antismash -h (do something with it)\n",
    "    - conda deactivate \n",
    "    - antismash --help-showall \n",
    "    - --genefinding-gff3\n",
    "- checked and recorded the results of assembly and annotation runs. Runs that seemed to run well had Preprocessing directory removed. So far only one run had a problem where the .se. was empty \n",
    "- scp -r 14108550@146.50.10.60:/home/14108550/personal/Samples_Outputs .\n",
    "\n",
    "\n",
    "__Sept 20__\n",
    "\n",
    "- tried an antiSMASH run, not successful: \n",
    "> antismash /scratch/slopez/T_722_5_output/Assembly/mg.assembly.merged.fa --genefinding-gff3 /scratch/slopez/T_722_5_output/Analysis/annotation/annotation_CDS_RNA_hmms.gff -c 8 \n",
    "\n",
    "  --genefinding-gff3 GFF3_FILE\n",
    "                        Specify GFF3 file to extract features from.\n",
    "\n",
    "__Sept 21__\n",
    "\n",
    "- 9:30 meeting with Anna \n",
    "  - faulty assembly run\n",
    "  - how to run antiSMASH in computation nodes -> do not run in the nodes, copy the data from scratch to my personal directory since it's not a lot (2 input files) and run in head node \n",
    "  - use the annotation.filt.gff instead of the _CDS_RNA_hmms.gff because the .filf. is produced earlier in the annotation process so it is more raw data and also doesn't have to wait for the other to go into antiSMASH (i'm guess for the IMP3 pipeline)\n",
    "  - using a subset of the long contigs, since the chances of antiSMASH of finding something useful comes from longer contigs\n",
    "    - use BBmap script: __reformat.sh__ on the assembly output file \n",
    "    - min-length=10,000 bp to make the long.toy.assembly dataset, fastaminlen=1\n",
    "    - then use this assembly file to filter the annotation file, to only include those genes. \n",
    "  - could also do a small version of the long contigs (increasing the filtering length?)\n",
    "  - Do a random contigs subset so see what antiSMASH finds\n",
    "- checked all samples and found that most of them do not have the preprocessing mg.se file in order to run the assemblies in IMP3 \n",
    "- filtered mg.assembly.merged.fa to mg.assembly.merged.length_filtered.fa with 10,000 bp threshold \n",
    "> reformat.sh in=mg.assembly.merged.fa out=mg.assembly.merged.length_filtered.fa minlength=10000\n",
    "> java -ea -Xms300m -cp /zfs/omics/software/packages/bbmap/current/ jgi.ReformatReads in=mg.assembly.merged.fa out=mg.assembly.merged.length_filtered.fa minlength=10000\n",
    ">Executing jgi.ReformatReads [in=mg.assembly.merged.fa, out=mg.assembly.merged.length_filtered.fa, minlength=10000]\n",
    ">Input is being processed as unpaired\n",
    ">Input:                  \t2184108 reads          \t1337527992 bases\n",
    ">Short Read Discards:    \t2182763 reads (99.94%) \t1310291179 bases (97.96%)\n",
    ">Output:                 \t1345 reads (0.06%) \t27236813 bases (2.04%)\n",
    ">Time:                         \t9.524 seconds.\n",
    ">Reads Processed:       2184k \t229.33k reads/sec\n",
    ">Bases Processed:       1337m \t140.44m bases/sec\n",
    "\n",
    "__Sept 22__\n",
    "\n",
    "- wrote script to filter annotations based on assembly, which was previously filtered by length \n",
    "- filtered the annotations:\n",
    "> python3 gff_filtering.py T_712_2/annotation.filt.gff T_712_2/mg.assembly.merged.length_filtered.fa T_712_2/annotation.assembly_filt.gff\n",
    "- Meeting with Bora 14:00 \n",
    "  - filter preprocessing parameters\n",
    "  - mapping rate \n",
    "  - story line of project and experiments \n",
    "- tried antismash again, with filtered files \n",
    "> conda activate /zfs/omics/projects/metatools/TOOLS/miniconda3/envs/antismash6/\n",
    "> antismash mg.assembly.merged.length_filtered.fa --genefinding-gff3 annotation.assembly_filt.gff -c 8\n",
    "> WARNING  22/09 15:32:13   Fasta header too long: renamed \"test_contig_2179645\" to \"c01344_test_co..\" \n",
    "\n",
    "\n",
    "__Sept 23__\n",
    "\n",
    "- look into the antiSMASH output (took 15 mins) - look into the other parameters that can be used - looking at antiSMASH documentation \n",
    "- look into the config files of preprocessing - bora - also the errout log files to see if something went wrong in the preprocessing resulting in empty mg.se files \n",
    "- set up overleaf latex document for thesis \n",
    "- finish metagenomics 101 lectures \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 4 Sept 26 - Sept 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sept 26__\n",
    "\n",
    "- check bora's output to see if there are errors in processing the residuals \n",
    "- antiSMASH documentation - runs parameters - output html viewing \n",
    "- submit assemblies to queue \n",
    "\n",
    "__Sept 27__\n",
    "\n",
    "- 1 pm meeting with Anna \n",
    "    - accept job for the first 3 months \n",
    "    - scratch storage time limit? \n",
    "    - Bora's output errors, maybe she deleted them? couldn't find anything indicating that the residual processing went wrong \n",
    "    - check if the regions found in the antiSMASH output match the ones found in the IMP3 annotation and if not how different are they\n",
    "    - look into how to compare the assemblies and annotations outputs statistically\n",
    "    - move scratch data to IMP3 folder in phb directory \n",
    "    - scp 14108550@omics-h0.science.uva.nl:/zfs/omics/projects/phb/bora/test/all_samples/T_CCD8_9/Stats\n",
    "    - check if antiSMASH can output the data in gff or other format than gbk \n",
    "\n",
    "- phiX174 is a bacterio phage \n",
    "\n",
    "__Sept 28__\n",
    "\n",
    "- Metagenomics 101: Lecture 8: Functional Profiles\n",
    "\n",
    "__Sept 29__\n",
    "\n",
    "\n",
    "__Sept 30__\n",
    "\n",
    "- BDA group meeting at 9 am "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 5 Oct 3 - Oct 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oct 3__\n",
    "\n",
    "- catch up\n",
    "\n",
    "__Oct 4__\n",
    "\n",
    "- 9 am meeting Anna \n",
    "- make a script to translate gbk files to gff to input back into the IMP3 pipeline \n",
    "\n",
    "__Oct 5__\n",
    "\n",
    "\n",
    "__Oct 6__\n",
    "\n",
    "- finished script to write a matrix(DataFrame) functional profile of the mapped reads to the annottion database outputs \n",
    "- make a script to \n",
    "\n",
    "__Oct 7__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6 Oct 10 - Oct 14 \n",
    "\n",
    "Unlocking working directory.\n",
    "Final resource settings:\n",
    "maximal number of cores: 1\n",
    "normal mem: 8G\n",
    "big mem: 8G\n",
    "big mem cores: 1\n",
    "big mem total: 128G\n",
    "/zfs/omics/projects/metatools/TOOLS/IMP3/.\n",
    "Unlocking working directory.\n",
    "\n",
    "wednesday at 10 meeting \n",
    "\n",
    "- make a clustering of the read counts between the functional groups found from the functional profiles \n",
    "- or make a clustering of the functional profiles based on the mapped counts \n",
    "\n",
    "Oct 21st\n",
    "- read up on functional profile matrix processing for normalization of data and how to perform statistical analysis \n",
    "- finished making all the config files to run the last assemblies. also did the dry runs for the remaining config files. waiting for the current assemblies to finish "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. plot distribution of all feature for all samples\n",
    "2. how many 0s?\n",
    "3. total read counts \n",
    "    - sum-normalization \n",
    "    - hellinger-transform\n",
    "    - DA-normalization\n",
    "    - CLR before PCA/for PCA \n",
    "    - pseudo count the 0s \n",
    "    - also to do centering and scaling \n",
    "\n",
    "thursday meeting 9:30 am Anna \n",
    "- plot a hist of 0s in rows \n",
    "\n",
    "Next week: 11am monday and 1:30 friday meetings with anna \n",
    "\n",
    "1:30 monday \n",
    "\n",
    "Nov 14\n",
    "\n",
    "did: to copy all the dbCAN annotation files into a single folder and download then to make the functional profiles \n",
    "ls -d T_* > dbCAN_output/IMP3_samples.tsv  (to get the list of all samples directories into a tsv file to read in below for loop)\n",
    "for i in `cat IMP3_samples.tsv`; do cp /zfs/omics/projects/phb/bora/IMP3/$i/Analysis/annotation/mg.dbCAN.counts.tsv $i.tsv;echo $i; done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dec 8 \n",
    "grep \"db_xref\" T_712_11/mg.Pfam.counts.gff | sed 's#.*db_xref=\\([^;]*\\).*#\\1#' | tr ',' '\\n' | sort | uniq -c | sort -n\n",
    "- used the code to obtain the most frequent pfam identifiers in the gff file to compare against another sample - observed that they are indeed very similar. \n",
    "\n",
    "\n",
    "Dec 13 \n",
    "\n",
    "cp -rp SAMPLE_FOLDER SAMPLE_BACKUP_FOLDER\n",
    "-- to copy a directory with the original time stamps instead of without -rp which only copies the files as they are and adding a time stamp of the moment they were copied \n",
    "\n",
    "/zfs/omics/projects/metatools/TOOLS/IMP3/workflow/rules/Analysis/antismash.smk and /zfs/omics/projects/metatools/TOOLS/IMP3/workflow/rules/Analysis/featureCount.smk as well as /zfs/omics/projects/metatools/TOOLS/IMP3/workflow/scripts/antismash_gff_filtering.py and /zfs/omics/projects/metatools/TOOLS/IMP3/workflow/scripts/antismash_gbk_parsing.py\n",
    "\n",
    "files with the incorporated antiSMASH into IMP3 pipeline \n",
    "\n",
    "VIGS_meta.csv from Bora contains strigolactone levels. also expected greatest effect on 712 treatment group. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaAsLin2 requires two input files, one for taxonomic or functional feature abundances, and one for sample metadata.\n",
    "- comprehensive R package for efficiently determining multivariable association between phenotypes, environments, exposures, covariates and microbial meta-omics features. MaAsLin 2 relies on general linear models to accommodate most modern epidemiological study designs, including cross-sectional and longitudinal, along with a variety of data exploration, normalization, and transformation methods.\n",
    "- In a cross-sectional study you collect data from a population at a specific point in time; in a longitudinal study you repeatedly collect data from the same sample over an extended period of time.\n",
    "- statistical power in the presence of repeated measures and multiple covariates, while accounting for the nuances of meta-omics features and controlling false discovery.\n",
    "- models: \n",
    "| Model | Data Type | Normalization | Transformation |\n",
    "| --- | --- | --- | --- |\n",
    "| LM (linear model) | count and non-count | TSS (total sum scaling), CLR, NONE | LOG, LOGIT (inverse of log), AST (arcsine square root-transformed), NONE | \n",
    "| CPLM (Compound Poisson linear model) | count and non-count | TSS, TMM (trimmed mean of M values), CLR, NONE | NONE | \n",
    "| NEGBIN (negative binomial model) | count | TMM, CLR, NONE | NONE | \n",
    "| ZINB (zero-inflated negative binomial regression model) | count | TMM, CLR, NONE | NONE | \n",
    "\n",
    "1. Data (or features) file\n",
    "- This file is tab-delimited.\n",
    "- Formatted with features as columns and samples as rows.\n",
    "- The transpose of this format is also okay.\n",
    "- Possible features in this file include microbes, genes, pathways, etc.\n",
    "2. Metadata file\n",
    "- This file is tab-delimited.\n",
    "- Formatted with features as columns and samples as rows.\n",
    "- The transpose of this format is also okay.\n",
    "\n",
    "## MaAsLin2 results:\n",
    "- coef column: signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding other variables in the model constant. in this case the independent variable is the group (control or T_712) and the dependent is the counts of reads per functional group. \n",
    "- The FDR is the rate that features called significant are truly null. An FDR of 5% means that, among all features called significant, 5% of these are truly nul. The total number of rejections of the null include both the number of false positives (FP) and true positives (TP). Simply put, FDR = FP / (FP + TP).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week of Jan 9 - Jan 13 \n",
    "Meeting with Anna - talked about how to pick the right PCAs and to continue with analysis of functional profiles, specially from antiSMASH output\n",
    "also mentioned how to include the strigolactone levels in the analysis by finding a direct correlation with the counts of significant functional groups, to plot them individually\n",
    "Also discussed to add permanova analysis to PCA visuals for completion\n",
    "\n",
    "Worked on functional profiles analysis and found out that there was something else wrong with the gbk parsing, it was adding two consecutive ; in some db_xref lines, making it not possible to identify and apply featureCounts. now all samples are in antiSMASH functional profile for Pfam annotation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0dd84e6e4655a1be09e25480d2aa07830f784093fb8ac0847c23715d011b335f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
