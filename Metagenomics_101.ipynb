{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metagenomics 101 course\n",
    "- https://staff.fnwi.uva.nl/a.u.s.heintzbuschart/metagenomics_00.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lecture 1: https://video.uva.nl/media/Metagenomics+101+-+1%7C+overview+-+private+version/0_pvgszh0o \n",
    "    - definition of metagenomics\n",
    "    - brief history of metagenomics\n",
    "    - glimpse into raw data\n",
    "    - typical steps in an analysis\n",
    "- Tutorial 1:\n",
    "    - Set up: didn't initialize miniconda since it had already been used before and saved data in personal directory.\n",
    "        - First test-run of IMP3 in Crunchomics - dry run to test configuration_\n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d my.config.yaml\n",
    "            - desired output: This was a dry-run (flag -n). The order of jobs does __not__ reflect the order of execution.\n",
    "        - Submitted the first test run to the compute nodes of crunchomics server in node 3 with omics-cn003.\n",
    "            - first check the available nodes: sinfo -o \"%n %e %m %a %c %C\" \n",
    "        - IMP3 inputs: data and configuration file \n",
    "            - my.config.yaml configuration file is the only required argument and specifies the input data. \n",
    "            - code used to commit the real run to the compute node, which includes more arguments than the previous dry run: \n",
    "                - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn002 my.config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lecture 2: Raw Data Preprocessing and QC \n",
    "        - .fastq files tools resource: http://barcwiki.wi.mit.edu/wiki/SOPs/qc_shortReads \n",
    "        - brief look into different sequencing techniques\n",
    "        - what can go wrong when sequencing\n",
    "        - sequencing quality scores\n",
    "        - quality reports\n",
    "        - adapter, spike-in, and host genome removal (the host microbiome needs to be removed because you are interested in the other genomes in the sample)\n",
    "- Tutorial 2: Run Preprocessing on Toy Data\n",
    "    - Finding Novaseq file in reads data - the GCEF.test.r1.fq and GCEF.test.r2.fq are novaseq\n",
    "    - code used to modify the configuration file __prep.1.config.yaml__ to use datasets COSMIC_vag.test.r1.fq and COSMIC_vag.test.r2.fq instead of the default test data, by manually changing inside the configuration file by using nano command: \n",
    "        - raws:\n",
    "            Metagenomics: \"/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r1.fq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r2.fq\"\n",
    "    - made a copy of prep.1.config.yaml to be able to run both configuration at the same time and have their own output directories. \n",
    "    - code used to modify the configuration file __prep.2.config.yaml__ to use datasets GCEF.test.r1.fq and GCEF.test.r2.fq instead of the default test data, by manually changing inside the configuration file by using __nano__ command: \n",
    "        - raws:\n",
    "            Metagenomics: \"/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/GCEF.test.r1.fq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/GCEF.test.r2.fq\"\n",
    "        - also changed the output directory to __IMP3_test_preprocessing_novaseq__, and nextseq argument to __true__. \n",
    "    - performed the dry run and obtained desired output:\n",
    "        - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d prep.1.config.yaml \n",
    "        - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d prep.2.config.yaml \n",
    "    - both runs were commited to node 2:\n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn002 prep.1.config.yaml\n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn002 prep.2.config.yaml\n",
    "    - The dataset COSMIC_vag.test.r1|2.fq comes from a sample that contains still host genomics DNA\n",
    "        - prep.1.config.yaml was copied to prep.3.config.yaml and a new configuration was specified with the same test data, a new output directory __IMP3_test_preprocessing_hg38filtering__, and the filtering was specified to hg38 to filter out the human genome \n",
    "        - dry run was performed and successful \n",
    "        - run was submitted to node 4: \n",
    "            - /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTRUN -b omics-cn004 prep.3.config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lecture 3: Mapping Metagenomics read data to reference genomes \n",
    "    - why mapping\n",
    "    - bioinformatics for sequence alignment\n",
    "    - look at output (alignments) created by read mappers\n",
    "    - what can be done with the output  \n",
    "- Tutorial 3:\n",
    "    - not IMP3 pipeline but the commands on their own  \n",
    "    - environments IMP3 provides on crunchomics to preprocess data with BWA-MEM - Burrows Wheeler algoritm (transform) - Maximum Exact Matches \n",
    "    1. Running BWA-MEM indexing \n",
    "        - build index of references (don't do on the frontend if using a real genomes, okay now bc test data)\n",
    "        - cp /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/REFERENCES/mg.assembly.merged.fa . (copied to my personal directory)\n",
    "        - conda activate /zfs/omics/projects/metatools/TOOLS/IMP3/conda/76e02d85877600c41ac84cb7bc27a189\n",
    "        - bwa index mg.assembly.merged.fa \n",
    "    2. Running mapping with BWA-MEM \n",
    "        - bwa mem -v 1 -t 1  mg.assembly.merged.fa /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.1.fastq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.2.fastq >> test_alignment.sam\n",
    "        - you can run other data, for examble: COMSIC_vag.test.r1|r2.fq with the hg38.fa - first need to find hg38.fa file to copy to personal directory and index it \n",
    "    3. Take a look at the alignment file \n",
    "        - output of BWA-MEM is an alignment file in .sam format. Alignment information is at the end of the file \n",
    "        - tail test_alignment.sam \n",
    "    4. Converting the alignment file to a binary (compressed) format \n",
    "        - convert to .bam format because the .sam is very big and you don't want to store on own disk \n",
    "        - samtools view --threads 1 -bS test_alignment.sam > test_alignment.bam\n",
    "        - can also be donde in one step with the mapping:                 - bwa mem -v 1 -t 1  /zfs/omics/projects/metatools/DB/filtering/hg38.fa /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r1.fq /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/COSMIC_vag.test.r2.fq |\\\n",
    "                    samtools view --threads 1 -bS - > COSMIC_alignment.bam\n",
    "        - can look at a .bam file with samtools view: samtools view test_alignment.bam | less\n",
    "    5. Filtering the .bam file \n",
    "        - also using samtools view, use -f 4 to find only reads which don't map to reference \n",
    "        - samtools view -f 4 test_alignment.bam | less \n",
    "        - this shows many of the values to be 0 \n",
    "        - -F 4 give reads which map (careful, there's also a second read)\n",
    "        - more samtools flags: https://broadinstitute.github.io/picard/explain-flags.html\n",
    "        - samtools manual: http://www.htslib.org/doc/samtools-view.html \n",
    "    6. More complex filtering \n",
    "        - used in IMP3 to remove reads mapping to a host genome \n",
    "        - samtools merge --threads 1 -u - \\\n",
    "            <(samtools view --threads 1 -u  -f 4 -F 264 COSMIC_alignment.bam) \\\n",
    "            <(samtools view --threads 1 -u -f 8 -F 260 COSMIC_alignment.bam) \\\n",
    "            <(samtools view --threads 1 -u -f 12 -F 256 COSMIC_alignment.bam)  | \\\n",
    "            samtools view --threads 1 -bF 0x800 - | \\\n",
    "            samtools sort --threads 1 -m 3G -n - | \\\n",
    "            bamToFastq -i stdin -fq COSMIC_filtered.r1.fq -fq2 COSMIC_filtered.r2.fq\n",
    "\n",
    "            conda deactivate \n",
    "            (all COSMIC_alignment.bam files are the test_alignment.bam files when doing the alignment of COSMIC files to the hg38.fa reference genome - didn't actually perform that alignment) (figure out what the code on top is doing by looking at the resources of flags and samtools documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lecture 4: Taxonomy\n",
    "    - different approaches toprofile microbiomes in terms of the present taxa, using metagenomics read data \n",
    "    - introduction into the aims and particular environments \n",
    "    - a touch of taxonomy \n",
    "    - brief reminder of mapping of metagenomis reads \n",
    "    - look at non-alignment based profilers \n",
    "    - how taxonomic profilers are benchmarked \n",
    "    - what we can do with this output \n",
    "- Tutorial 4: Run mOTUs2, MetaPhlan2, and kraken2\n",
    "    - Use the taxonomic profiles in the IMP3 pipeline as well as MetaPhlan3 (IMP3 in crunchomics and metaphlan3 conda environment)\n",
    "    - use cd /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS files or the preprocessed files from the last sessions\n",
    "    - Running taxonomic profiling within __IMP3__ \n",
    "        - start IMP3 with an appropriate configuration file since data is preprocessed. Set config file to not do preprocessing, and set input as already preprocessed files\n",
    "        > cp /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/04_taxonomy1/tax.config.yaml my.tax.config.yaml \n",
    "        - change (using nano) to input own data. Can also change the kraken databse to one of the names in /zfs/omics/projects/metatools/DB with the word kraken in it (UHGP_kraken2 for human gut genomes, minikraken2 for an even smaller database; kraken_pfp8 is the current kraken db in configuration). Output directory: test_tax_output\n",
    "            >raws:\n",
    "            >>Metagenomics: /home/14108550/personal/IMP3_test_preprocessing/Preprocessing/mg.r1.trimmed.phiX174_filtered.fq\n",
    "            >>/home/14108550/personal/IMP3_test_preprocessing/Preprocessing/mg.r2.trimmed.phiX174_filtered.fq\n",
    "            >>/home/14108550/personal/IMP3_test_preprocessing/Preprocessing/mg.se.trimmed.phiX174_filtered.fq\n",
    "        - first did dry run, which was successful \n",
    "            > /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -d my.tax.config.yaml\n",
    "        - then commited run to node 3 \n",
    "            > /zfs/omics/projects/metatools/TOOLS/IMP3/runIMP3 -c -r -n TESTTAX -b omics-cn003 my.tax.config.yaml\n",
    "        - inside the output directory will be another directory Analysis/taxonomy which holds the outputs from mOTUs2 and kraken2 \n",
    "        - Taxonomic profiling using __MetaPhlan3__ \n",
    "            - works very well on human samples and has a strain-level module. \n",
    "            - activate the conda environment: \n",
    "            > conda activate /zfs/omics/projects/metatools/TOOLS/miniconda3/envs/metaphlan-3.0\n",
    "            - to get help and documentation on the profiler:\n",
    "            > metaphlan -h \n",
    "            - example to run on filtered test reads:\n",
    "            > metaphlan /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/FILTERED_READS/mg.r1.trimmed.phiX174_filtered.fq,/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/FILTERED_READS/mg.r2.trimmed.phiX174_filtered.fq,/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/FILTERED_READS/mg.se.trimmed.phiX174_filtered.fq --bowtie2out filtered_test.bowtie2.bz2 --input_type fastq -o profile.filtered_test.txt  --bowtie2db /zfs/omics/projects/metatools/DB/metaphlan --unknown_estimation\n",
    "            - can also run on own filtered reads instead. to run on real data set, put the commands to activate (and deactivate) conda and the metaphlan command into a script that you submit to the cluster. You can then also choose to set the --nproc argument (--nproc 8 to parallelize the profiling) \n",
    "            - code for runnin the non-filtered reads \n",
    "            > metaphlan /zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.r1.fastq,/zfs/omics/projects/metatools/SANDBOX/Metagenomics101/EXAMPLE_DATA/READS/test.mg.r2.fastq --bowtie2out unfiltered_test.bowtie2.bz2 --input_type fastq -o profile.unfiltered_test.txt  --bowtie2db /zfs/omics/projects/metatools/DB/metaphlan --unknown_estimation\n",
    "            - To merge the profiles from several samples (or in this case, the same sample, but represented by filtered or unfiltered reads), you can use metaphlan’s merge script\n",
    "            > merge_metaphlan_tables.py profile*filtered_test.txt > merged_abundance.test.tsv\n",
    "            - to compare the results:\n",
    "            > less merged_abundance.test.tsv\n",
    "            > conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Metagenomics 101 Lecture 5: Assembly\n",
    "    - lecture video: https://video.uva.nl/media/Metagenomics+101+-+5%7C+Assembly+-+private+version/0_p8gnde38 \n",
    "    - why assemble\n",
    "    - alternatives to assembly\n",
    "    - how does assembly work\n",
    "    - how to inspect assemblies\n",
    "    - what to assemble \n",
    "    - stopped at min 17 \n",
    "- Tutorial 5: Run assemblies in IMP3 \n",
    "    - assemble with IMP3 and look at diagnostic plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Metagenomics Lecture 6: Metagenome Annotation (of assembled contigs)\n",
    "    - finding bacterial genes\n",
    "        - protein coding genes\n",
    "        - rRNAs\n",
    "    - annotating genes with functions\n",
    "        - why not just align?\n",
    "        - HMMs and HMMER\n",
    "- Tutorial 6: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Metagenomics 101 Lecture 7 \n",
    "  - approaches to make (semi-)quantitative profiles of the molecular functions found in metagenomes and how they can be compared across samples\n",
    "  - review on mapping and annotation\n",
    "  - gene abundance measures - functional profile calculation:\n",
    "    - reads per gene/reads per function\n",
    "    - reads per kilobase\n",
    "    - copies per million\n",
    "    - average depth of coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Metagenomics 101: Lecture 8: Functional Profiles\n",
    "    - approaches to make (semi-)quantitative profiles of the molecular functions found in metagenomes, and how they can be compared across sambles\n",
    "    - look back at mapping and annotation\n",
    "    - Gene abundance measures - functional profile calculation\n",
    "        - reads per gene/reads per functin\n",
    "        - reads per kilobase\n",
    "        - copies per million\n",
    "        - average depth of coverage\n",
    "    - working with functional profiles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
